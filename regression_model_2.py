# -*- coding: utf-8 -*-
"""AntibodyBindingEnergyRegressionModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N2t4JCxG1uFA__bM3Hu4RoD6_Dvhn_sP
"""
print('AbReg - Run regression model')

import time
import os
import numpy as np
import torch
import torch.nn as nn
import keras
from keras.models import Sequential
from keras.layers import Dense
import workflow
from embedding_generator import EmbeddingGenerator

name = 'seq85k'
use_cpu = False

# df = workflow.import_energy_metadata()
foldx_dict = workflow.import_energy_metadata_foldx()
seqs = workflow.get_embedding_list(name)
np.random.shuffle(seqs) # ensure random order

input_shape = 585782

dropout = .2

def RegressionModel():
    X_input = keras.Input(shape=input_shape)

    # X = keras.layers.Lambda(lambda batch: workflow.load_embeddings(name, batch))(X_input)
    X = keras.layers.Dropout(dropout)(X_input)

    for _ in range(8):
        X = Dense(800, activation='relu', kernel_initializer="he_uniform")(X)
        X = keras.layers.LayerNormalization(axis=-1)(X)
        X = keras.layers.Dropout(dropout)(X)

    X = Dense(700, activation='relu', kernel_initializer="he_uniform")(X)
    X = keras.layers.BatchNormalization(axis=-1, momentum=0.99)(X)
    X = keras.layers.Dropout(dropout)(X)

    X = Dense(400, activation='relu', kernel_initializer="he_uniform")(X)
    X = keras.layers.BatchNormalization(axis=-1, momentum=0.99)(X)
    X = keras.layers.Dropout(dropout)(X)

    X = Dense(2, kernel_initializer="he_uniform")(X)

    model = keras.Model(inputs = X_input, outputs = X, name='RegressionModel')

    return model

print('AbReg - Initialize model')
model = RegressionModel()

print('AbReg - Compile model')
model.compile(optimizer='adam', loss=keras.losses.MeanSquaredError())


batch_size = 256 # 16-1024

# For entire dataset
train_data = EmbeddingGenerator(name, seqs[:80000], foldx_dict, batch_size)

# For testing smaller subset of data
# train_data = EmbeddingGenerator(name, seqs[:1000], foldx_dict, batch_size)

valid_data = EmbeddingGenerator(name, seqs[80000:81000], foldx_dict, batch_size)
test_data = EmbeddingGenerator(name, seqs[81000:82000], foldx_dict, batch_size)


# train_data = EmbeddingGenerator(name, seqs[:-2000], foldx_dict, batch_size)
# valid_data = EmbeddingGenerator(name, seqs[-2000:-1000], foldx_dict, batch_size)
# test_data = EmbeddingGenerator(name, seqs[-1000:], foldx_dict, batch_size)

print('AbReg - Train model')
model.fit(train_data, validation_data=valid_data, epochs=1)

timestamp = time.strftime('%m%d_%H%M', time.localtime(time.time()))
model_fp = os.path.join('models', 'abreg_' + timestamp)

print('AbReg - Save model to file %s' % model_fp)
model.save(model_fp)

# to reload
# model = keras.models.load_model('models/abreg_1116_1545')

model.trainable = False

print('AbReg - Evaluate model')
model.evaluate(test_data)

# traintest = EmbeddingGenerator(name, seqs[500:600], foldx_dict, batch_size)

# for subset_200_seq85k, try batch size = 16 
# 12/12 [==============================] - 5s 450ms/step - loss: 27.4618



predictions = {}
prediction_types = [
    'random_generated',
    'substitution_generated',
    'model_predict_seqs_2_1117_0632',
    'model_predict_seqs_3_1117_0703',
    'model_predict_seqs_4_1117_0721'
]

for n in prediction_types:
    print('AbReg - Predict generated embeddings: ' + n)
    labels = workflow.get_embedding_list(n)
    # Note: batch size *must* not be larger than data size
    predicted_embeddings = EmbeddingGenerator(n, labels, foldx_dict, len(labels), include_targets=False)
    predicted_energies = model.predict(predicted_embeddings)
    predictions[n] = predicted_energies

# print('AbReg - Evaluate predicted binding energy of generated embeddings')
# for n,e in predictions.items():
#     print('\nPredicted energies for ' + n)
#     print('Mean: ' + str(np.mean(e, axis=0)))
#     print('Stdev: ' + str(np.sqrt(np.var(e, axis=0))))

#     el1 = list(e)
#     el1.sort(key = lambda x: x[0])
#     el2 = list(e)
#     el2.sort(key = lambda x: x[1])
#     print('Best whole-model FoldX: ' + str(el1[0]))
#     print('Best interface-only FoldX: ' + str(el2[0]))
#     print('Worst whole-model FoldX: ' + str(el1[-1]))
#     print('Worst interface-only FoldX: ' + str(el2[-1]))


print('AbReg - Evaluate predicted whole-model binding energy of generated embeddings')
for n,e in predictions.items():
    print('\nPredicted energies for ' + n)
    print('Mean: ' + str(np.mean(e, axis=0)[0]))
    print('Stdev: ' + str(np.sqrt(np.var(e, axis=0))[0]))

    el1 = list(e)
    el1.sort(key = lambda x: x[0])
    print('Best whole-model FoldX: ' + str(el1[0][0]))
    print('Worst whole-model FoldX: ' + str(el1[-1][0]))
