# -*- coding: utf-8 -*-
"""AntibodyBindingEnergyRegressionModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N2t4JCxG1uFA__bM3Hu4RoD6_Dvhn_sP
"""

import numpy as np
import torch
import torch.nn as nn
import keras
from keras.models import Sequential
from keras.layers import Dense
import workflow
from embedding_generator import EmbeddingGenerator

name = 'seq85k'
use_cpu = False

# df = workflow.import_energy_metadata()
foldx_dict = workflow.import_energy_metadata_foldx()
seqs = workflow.get_embedding_list(name)
np.random.shuffle(seqs) # ensure random order

batch_size = 128
input_shape = 585782

dropout = .2

def RegressionModel():
    X_input = keras.Input(shape=input_shape)

    # X = keras.layers.Lambda(lambda batch: workflow.load_embeddings(name, batch))(X_input)
    X = keras.layers.Dropout(dropout)(X_input)

    for _ in range(5):
        X = Dense(1000, activation='relu', kernel_initializer="he_uniform")(X)
        X = keras.layers.BatchNormalization(axis=-1, momentum=0.99)(X)
        X = keras.layers.Dropout(dropout)(X)

    X = Dense(800, activation='relu', kernel_initializer="he_uniform")(X)
    X = keras.layers.BatchNormalization(axis=-1, momentum=0.99)(X)
    X = keras.layers.Dropout(dropout)(X)

    X = Dense(700, activation='relu', kernel_initializer="he_uniform")(X)
    X = keras.layers.BatchNormalization(axis=-1, momentum=0.99)(X)
    X = keras.layers.Dropout(dropout)(X)


    X = Dense(400, activation='relu', kernel_initializer="he_uniform")(X)
    X = keras.layers.BatchNormalization(axis=-1, momentum=0.99)(X)
    X = keras.layers.Dropout(dropout)(X)


    X = Dense(2, kernel_initializer="he_uniform")(X)

    model = keras.Model(inputs = X_input, outputs = X, name='RegressionModel')

    return model

model = RegressionModel()

model.compile(optimizer='adam', loss=keras.losses.MeanSquaredError())



'''
smaller subset for testing
batch_size = 32 # or 16
train_data = EmbeddingGenerator(name, seqs[:-80000], df, batch_size) # -2000
valid_data = EmbeddingGenerator(name, seqs[-200:-100], df, batch_size) # -2000,-1000
test_data = EmbeddingGenerator(name, seqs[-100:], df, batch_size)
'''

train_data = EmbeddingGenerator(name, seqs[:-2000], df, batch_size)
valid_data = EmbeddingGenerator(name, seqs[-2000:-1000], df, batch_size)
test_data = EmbeddingGenerator(name, seqs[-1000:], df, batch_size)


model.fit(train_data, validation_data=valid_data, epochs=1)
model.evaluate(test_data)

traintest = EmbeddingGenerator(name, seqs[500:600], foldx_dict, batch_size)


# for subset_200_seq85k, try batch size = 16 
# 12/12 [==============================] - 5s 450ms/step - loss: 27.4618